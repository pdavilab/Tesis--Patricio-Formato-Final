\chapter{Conclusiones}
\label{ch:conclusions}

Los modelos de grafos aleatorias exponenciales son una herramienta más en el repertorio de herramientas de los estadísticos y no son una panacea. Mientras que nos gustaría pensar que podemos usar este tipo de modelos para modelar todo tipo de fenómenos aún tienen muchas limitaciones cuando no tenemos acceso a las estadísticas correctas. Es aún mas difícil encontrar las estadísticas adecuadas cuando nuestros modelos se tardan tiempo aproximadamente infinito en correr.

Sin embargo, esto no debería de ser sorprendente pues estamos intentando encontrar el modelo exponencial que sea capaz de reproducir las propiedades globales de un grafo a través de medidas locales. Además, es importante considerar que en la construcción del modelo es que asumimos por ejemplo en el grafo de amistades que la propensidad de todos nuestros agentes a hacer amigos es la misma a través del grafo, una limitación importante. En el caso empírico de Lotame entonces la inferencia sería que la forma en la que conceptualmente atamos nuestros modelos mentales y las preferencias de distintas audiencias, cada usuario tiene el mismo impacto sobre la composición de esta Grafo de conexiones que el siguiente. Algo que claramente no se cumple pues nuestras aristas se ven construidas de forma que elegimos combinaciones de dos en los n comportamientos de un solo usuario en cualquier momento del tiempo.

Además, la información que contienen estos registros posiblemente se verían mejor modelados con una mezcla de estadísticas temporales y los métodos de Grafos exponenciales valuadas y su uso de la distribución de Conway–Maxwell–Poisson (\cite{TERGMS}). Además de que para llevar a cabo un desarrollo que pueda correr un modelo sobre este gigantesco torrente de información se requeriría un equipo de ingeniería y creatividad como los que trabajan actualmente en Lotame, Hexagon Data o Salesforce. 

Otra dificultad con este problema es sobre poder generar una representación de un `espacio de conocimiento' o intereses que refleje el comportamiento agregado de todos los usuarios en internet. Este conjunto de `nodos platónicos' no es nada trivial. Realmente este problema de simulación y su adyacente problema de conglomerados funcionales podrían eludir nuestros modelos y implementaciones computacionales por un largo tiempo. 

Finalmente, con la muestra que se obtuvo de los datos de las \textit{cookies} en realidad el problema a resolver de encontrar comunidades en internet a partir de las relaciones entre ellas se vuelve trivial si es que simplemente se toman los subgrafos generados del grafo muestreado y se asume que estos subgrafos son en sí las comunidades que estamos buscando. Pues ahora ya no tenemos un interés real en saber las propiedades estadísticas de cada comunidad pues las variables de interés quedan claramente definidas. Una posibilidad para modelar este problema en el futuro sería entonces encontrar los subgrafos de los grafos inducidos a través de periodos temporales discretos y comparar la composición de los subgrafos a través del tiempo utilizando modelos temporales de Grafos aleatorias exponenciales.
 
